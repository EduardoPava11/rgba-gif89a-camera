package com.rgbagif.processing

import android.graphics.Bitmap
import android.graphics.Canvas
import android.graphics.Paint
import android.graphics.Rect
import android.util.Log
import com.rgbagif.config.AppConfig
import com.rgbagif.log.CanonicalLogger
import com.rgbagif.BuildConfig
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import kotlinx.serialization.Serializable
import kotlinx.serialization.encodeToString
import kotlinx.serialization.json.Json
import uniffi.m2down.M2TimingStats
import uniffi.m2down.M2QualityMetrics
import uniffi.m2down.`m2Downsize9x9Cpu`
import uniffi.m2down.`m2InitializeModel`
import uniffi.m2down.`getM2TimingStats`
import uniffi.m2down.`getM2QualityMetrics`
import uniffi.m2down.`getM2Version`
import uniffi.m2down.`resetM2Stats`
import java.io.File
import java.io.FileOutputStream
import java.text.SimpleDateFormat
import java.util.*

/**
 * M2 Neural Downsize Processor
 * Handles 729×729 → 81×81 downsampling via fixed 9×9 neural network
 * North Star spec: CPU-only, quality over speed with comprehensive metrics
 */
class M2Processor {
    companion object {
        private const val TAG = "M2Processor"
        
        init {
            if (AppConfig.useM2NeuralProcessing) {
                CanonicalLogger.logM2InitStart()
                
                // TODO: Fix UniFFI contract version mismatch
                // Temporarily disabled due to version mismatch error
                Log.w(TAG, "M2 neural processing temporarily disabled - UniFFI contract mismatch")
                CanonicalLogger.logM2InitFail("UniFFI contract version mismatch - using fallback")
                
                /*
                // JNI library loading with fail-fast for debug
                try {
                    System.loadLibrary("m2down")
                    val version = `getM2Version`()
                    CanonicalLogger.logJniOk("m2down", version)
                    
                    // Initialize neural network model
                    try {
                        `m2InitializeModel`()
                        CanonicalLogger.logM2InitSuccess(version)
                    } catch (e: Exception) {
                        CanonicalLogger.logM2InitFail(e.message ?: "unknown")
                    }
                } catch (e: UnsatisfiedLinkError) {
                    CanonicalLogger.logJniFail("m2down", e.message ?: "library not found")
                    if (BuildConfig.DEBUG) {
                        error("Rust/UniFFI not ready — see JNI_FAIL in logcat")
                    }
                }
                */
            } else {
                Log.i(TAG, "M2 neural processing disabled by configuration")
            }
        }
    }
    
    data class M2Result(
        val outputBitmap: Bitmap,
        val processingTimeMs: Long,
        val frameIndex: Int,
        val qualityMetrics: M2QualityMetrics? = null
    )
    
    data class M2SessionStats(
        val totalFrames: Int,
        val successfulFrames: Int,
        val totalTimeMs: Long,
        val averageTimeMs: Long,
        val timingStats: M2TimingStats? = null,
        val qualityMetrics: M2QualityMetrics? = null
    )
    
    @Serializable
    data class M2QualityReport(
        val sessionId: String,
        val totalFrames: Int,
        val processingStats: ProcessingStats,
        val qualityMetrics: QualityMetricsJson,
        val neuralStats: NeuralStats
    )
    
    @Serializable
    data class ProcessingStats(
        val totalDurationMs: Long,
        val avgFrameMs: Double,
        val minFrameMs: Double,
        val maxFrameMs: Double
    )
    
    @Serializable
    data class QualityMetricsJson(
        val avgSsim: Double,
        val avgPsnr: Double,
        val edgePreservation: Double
    )
    
    @Serializable
    data class NeuralStats(
        val policyConfidenceAvg: Double,
        val valuePredictionAvg: Double,
        val kernelDiversity: Double
    )
    
    private var sessionStats = M2SessionStats(0, 0, 0, 0)
    private val frameTimes = mutableListOf<Long>()
    private var sessionId: String = ""
    
    /**
     * Start a new M2 processing session
     */
    fun startSession(): String {
        val dateFormat = SimpleDateFormat("yyyyMMdd_HHmmss", Locale.US)
        sessionId = "M2_Session_${dateFormat.format(Date())}"
        
        // Reset statistics
        // TODO: Re-enable when UniFFI is fixed
        // `resetM2Stats`()
        resetStats()
        
        Log.i(TAG, "M2 session started: $sessionId")
        return sessionId
    }
    
    /**
     * Process a single 729×729 RGBA frame to 81×81
     */
    suspend fun processFrame(
        rgbaData: ByteArray,
        width: Int,
        height: Int,
        frameIndex: Int
    ): M2Result = withContext(Dispatchers.Default) {
        val startTime = System.currentTimeMillis()
        
        // Validate input dimensions
        require(width == AppConfig.CAPTURE_WIDTH) {
            "Invalid width: expected ${AppConfig.CAPTURE_WIDTH}, got $width"
        }
        require(height == AppConfig.CAPTURE_HEIGHT) {
            "Invalid height: expected ${AppConfig.CAPTURE_HEIGHT}, got $height"
        }
        require(rgbaData.size == width * height * 4) {
            "Invalid data size: expected ${width * height * 4}, got ${rgbaData.size}"
        }
        
        try {
            CanonicalLogger.logM2FrameBegin(frameIndex)
            
            // TODO: Re-enable when UniFFI contract is fixed
            /*
            // Convert ByteArray to List<UByte> for UniFFI
            val ubyteList = rgbaData.map { it.toUByte() }
            
            // Call Rust M2 downsize function with neural network
            val outputData = `m2Downsize9x9Cpu`(
                rgba729 = ubyteList,
                width = width.toUInt(),
                height = height.toUInt()
            )
            
            // Convert back to ByteArray
            val outputBytes = ByteArray(outputData.size) { i ->
                outputData[i].toByte()
            }
            */
            
            // Fallback: Simple downsampling for testing JPEG output
            val outputBytes = simpleDownsample(rgbaData, width, height, 
                AppConfig.EXPORT_WIDTH, AppConfig.EXPORT_HEIGHT)
            
            // Create output bitmap (81×81)
            val outputBitmap = createRGBABitmap(outputBytes, AppConfig.EXPORT_WIDTH, AppConfig.EXPORT_HEIGHT)
            
            val processingTime = System.currentTimeMillis() - startTime
            frameTimes.add(processingTime)
            
            // Try to get quality metrics from Rust M2 module
            // TODO: Re-enable when UniFFI is fixed
            val qualityMetrics = null /* try {
                `getM2QualityMetrics`()
            } catch (e: Exception) {
                null
            } */
            
            Log.d(TAG, "M2 processed frame $frameIndex in ${processingTime}ms (neural: ${qualityMetrics != null})")
            // Note: logM2FrameEnd will be called when file is actually saved in processSession
            
            return@withContext M2Result(
                outputBitmap = outputBitmap,
                processingTimeMs = processingTime,
                frameIndex = frameIndex,
                qualityMetrics = qualityMetrics
            )
            
        } catch (e: Exception) {
            CanonicalLogger.logM2FrameFail(frameIndex, e.message ?: "unknown")
            Log.e(TAG, "M2 processing failed for frame $frameIndex", e)
            throw IllegalStateException("M2 processing failed: ${e.message}", e)
        }
    }
    
    /**
     * Simple downsampling fallback when UniFFI is not available
     */
    private fun simpleDownsample(
        rgbaData: ByteArray,
        srcWidth: Int,
        srcHeight: Int,
        dstWidth: Int,
        dstHeight: Int
    ): ByteArray {
        val scaleX = srcWidth.toFloat() / dstWidth
        val scaleY = srcHeight.toFloat() / dstHeight
        val output = ByteArray(dstWidth * dstHeight * 4)
        
        for (y in 0 until dstHeight) {
            for (x in 0 until dstWidth) {
                val srcX = (x * scaleX).toInt().coerceIn(0, srcWidth - 1)
                val srcY = (y * scaleY).toInt().coerceIn(0, srcHeight - 1)
                
                val srcIdx = (srcY * srcWidth + srcX) * 4
                val dstIdx = (y * dstWidth + x) * 4
                
                // Copy RGBA values
                output[dstIdx] = rgbaData[srcIdx]         // R
                output[dstIdx + 1] = rgbaData[srcIdx + 1] // G
                output[dstIdx + 2] = rgbaData[srcIdx + 2] // B
                output[dstIdx + 3] = rgbaData[srcIdx + 3] // A
            }
        }
        
        return output
    }
    
    /**
     * Create RGBA bitmap from byte array
     */
    private fun createRGBABitmap(rgbaBytes: ByteArray, width: Int, height: Int): Bitmap {
        val bitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888)
        
        // Convert RGBA to ARGB for Android bitmap
        val argbBytes = ByteArray(rgbaBytes.size)
        for (i in rgbaBytes.indices step 4) {
            argbBytes[i] = rgbaBytes[i + 3]     // A
            argbBytes[i + 1] = rgbaBytes[i]     // R
            argbBytes[i + 2] = rgbaBytes[i + 1] // G
            argbBytes[i + 3] = rgbaBytes[i + 2] // B
        }
        
        val buffer = java.nio.ByteBuffer.wrap(argbBytes)
        bitmap.copyPixelsFromBuffer(buffer)
        return bitmap
    }
    
    /**
     * Process all frames in a session with full M2 deliverables
     */
    suspend fun processSession(
        frames: List<ByteArray>,
        outputDir: File,
        onProgress: (Int, Int) -> Unit = { _, _ -> }
    ): M2SessionStats = withContext(Dispatchers.IO) {
        val sessionStartTime = System.currentTimeMillis()
        var successCount = 0
        val processedBitmaps = mutableListOf<Bitmap>()
        
        // Create session directory structure
        val sessionDir = File(outputDir, sessionId)
        sessionDir.mkdirs()
        val downsizedDir = File(sessionDir, "downsized")
        downsizedDir.mkdirs()
        
        // Process each frame
        frames.forEachIndexed { index, frameData ->
            try {
                // Process frame with neural network
                val result = processFrame(
                    rgbaData = frameData,
                    width = AppConfig.CAPTURE_WIDTH,
                    height = AppConfig.CAPTURE_HEIGHT,
                    frameIndex = index
                )
                
                // Save as JPEG with exact naming convention (better compatibility)
                val jpegFile = File(downsizedDir, "frame_%03d.jpg".format(index))
                val jpegSaved = saveJpeg(result.outputBitmap, jpegFile, 95)
                
                // Log canonical M2 frame completion
                CanonicalLogger.logM2FrameEnd(
                    idx = index,
                    pngSuccess = jpegSaved,
                    path = jpegFile.absolutePath,
                    bytes = if (jpegFile.exists()) jpegFile.length() else 0L
                )
                
                // Store bitmap for mosaic generation
                processedBitmaps.add(result.outputBitmap)
                
                successCount++
                onProgress(index + 1, frames.size)
                
                Log.d(TAG, "Frame $index: ${result.processingTimeMs}ms")
                
            } catch (e: Exception) {
                Log.e(TAG, "Failed to process frame $index", e)
            }
        }
        
        // Generate deliverables
        generateDeliverables(sessionDir, processedBitmaps, successCount)
        
        // Connect M2→M3 Pipeline: Trigger M3 GIF export automatically
        // Accept any frame count (32, 81, etc.)
        if (AppConfig.useM3GifExport && processedBitmaps.isNotEmpty()) {
            try {
                Log.i(TAG, "Triggering M3 GIF export with ${processedBitmaps.size} frames...")
                val m3Processor = M3Processor()
                m3Processor.startSession()
                
                // Export optimized GIF
                val m3Result = m3Processor.exportOptimizedGif(
                    frames = processedBitmaps,
                    outputDir = sessionDir,
                    baseName = "final_output"
                )
                
                // Generate M3 diagnostic report
                m3Processor.generateDiagnosticReport(m3Result, sessionDir)
                
                Log.i(TAG, "M3 GIF export complete: ${m3Result.gifFile.name} (${m3Result.fileSize / 1024}KB)")
                
                // Log successful M2→M3 pipeline completion
                CanonicalLogger.logM3GifDone(
                    frames = m3Result.frameCount,
                    fps = 10, // 100ms delay = 10 FPS
                    sizeBytes = m3Result.fileSize,
                    loop = true,
                    path = m3Result.gifFile.absolutePath
                )
                
            } catch (e: Exception) {
                Log.e(TAG, "M3 GIF export failed", e)
                // Don't fail the entire M2 session if M3 fails
            }
        }
        
        val totalTime = System.currentTimeMillis() - sessionStartTime
        val avgTime = if (frameTimes.isNotEmpty()) {
            frameTimes.average().toLong()
        } else 0L
        
        // Get final timing and quality stats
        // TODO: Re-enable when UniFFI is fixed
        val timingStats = null // try { `getM2TimingStats`() } catch (e: Exception) { null }
        val qualityMetrics = null // try { `getM2QualityMetrics`() } catch (e: Exception) { null }
        
        sessionStats = M2SessionStats(
            totalFrames = frames.size,
            successfulFrames = successCount,
            totalTimeMs = totalTime,
            averageTimeMs = avgTime,
            timingStats = timingStats,
            qualityMetrics = qualityMetrics
        )
        
        Log.i(TAG, "M2 session complete: $successCount/${frames.size} frames in ${totalTime}ms")
        Log.i(TAG, "Average per frame: ${avgTime}ms, Neural confidence: N/A (UniFFI disabled)")
        
        return@withContext sessionStats
    }
    
    /**
     * Generate all required M2 deliverables per specification
     */
    private suspend fun generateDeliverables(
        sessionDir: File,
        processedBitmaps: List<Bitmap>,
        successCount: Int
    ) = withContext(Dispatchers.IO) {
        try {
            // 1. Diagnostic Mosaic: 9×9 grid showing all 81 frames
            generateDiagnosticMosaic(sessionDir, processedBitmaps)
            
            // 2. Timing Logs
            generateTimingLogs(sessionDir)
            
            // 3. Quality Metrics JSON
            generateQualityReport(sessionDir, successCount)
            
            Log.i(TAG, "M2 deliverables generated in: ${sessionDir.absolutePath}")
            
        } catch (e: Exception) {
            Log.e(TAG, "Failed to generate M2 deliverables", e)
        }
    }
    
    /**
     * Generate 729×729 mosaic showing all 81 frames in 9×9 grid
     */
    private fun generateDiagnosticMosaic(sessionDir: File, bitmaps: List<Bitmap>) {
        if (bitmaps.isEmpty()) return
        
        val mosaicSize = 729
        val cellSize = 81
        val gridSize = 9
        val borderWidth = 1
        
        val mosaicBitmap = Bitmap.createBitmap(mosaicSize, mosaicSize, Bitmap.Config.ARGB_8888)
        val canvas = Canvas(mosaicBitmap)
        val paint = Paint(Paint.ANTI_ALIAS_FLAG)
        
        // Black background
        canvas.drawColor(android.graphics.Color.BLACK)
        
        // Draw each frame in grid
        for (i in 0 until minOf(bitmaps.size, 81)) {
            val row = i / gridSize
            val col = i % gridSize
            
            val x = col * cellSize + borderWidth
            val y = row * cellSize + borderWidth
            
            val srcRect = Rect(0, 0, bitmaps[i].width, bitmaps[i].height)
            val dstRect = Rect(x, y, x + cellSize - borderWidth, y + cellSize - borderWidth)
            
            canvas.drawBitmap(bitmaps[i], srcRect, dstRect, paint)
        }
        
        // Save mosaic as JPEG for better compatibility
        val mosaicFile = File(sessionDir, "m2_mosaic.jpg")
        saveJpeg(mosaicBitmap, mosaicFile, 95)
        
        Log.d(TAG, "Generated diagnostic mosaic: ${mosaicFile.absolutePath}")
    }
    
    /**
     * Generate detailed timing logs per specification
     */
    private fun generateTimingLogs(sessionDir: File) {
        val timingFile = File(sessionDir, "m2_timing.log")
        // TODO: Re-enable when UniFFI is fixed
        val timingStats = null // try { `getM2TimingStats`() } catch (e: Exception) { return }
        if (timingStats == null) {
            timingFile.writeText("M2 timing logs unavailable - UniFFI disabled\n")
            Log.d(TAG, "Generated timing logs (fallback): ${timingFile.absolutePath}")
            return
        }
        
        // This code won't be reached since timingStats is always null, but kept for future
        Log.d(TAG, "Generated timing logs: ${timingFile.absolutePath}")
    }
    
    /**
     * Generate comprehensive quality metrics JSON
     */
    private fun generateQualityReport(sessionDir: File, successCount: Int) {
        val reportFile = File(sessionDir, "m2_quality.json")
        // TODO: Re-enable when UniFFI is fixed
        val timingStats = null // try { `getM2TimingStats`() } catch (e: Exception) { return }
        val qualityMetrics = null // try { `getM2QualityMetrics`() } catch (e: Exception) { return }
        if (timingStats == null || qualityMetrics == null) {
            // Since UniFFI is disabled, we can't access these metrics
            // Create dummy report for now
            val report = M2QualityReport(
                sessionId = sessionId,
                totalFrames = successCount,
                processingStats = ProcessingStats(
                    totalDurationMs = 0L,
                    avgFrameMs = 0.0,
                    minFrameMs = 0.0,
                    maxFrameMs = 0.0
                ),
                qualityMetrics = QualityMetricsJson(
                    avgSsim = 0.0,
                    avgPsnr = 0.0,
                    edgePreservation = 0.0
                ),
                neuralStats = NeuralStats(
                    policyConfidenceAvg = 0.0,
                    valuePredictionAvg = 0.0,
                    kernelDiversity = 0.0
                )
            )
            
            val json = Json { prettyPrint = true }
            reportFile.writeText(json.encodeToString(report))
            
            Log.d(TAG, "Generated quality report: ${reportFile.absolutePath}")
        }
    }
    
    /**
     * Save bitmap as PNG (lossless)
     */
    private fun savePng(bitmap: Bitmap, file: File) {
        FileOutputStream(file).use { out ->
            // PNG compression quality is ignored (always lossless)
            bitmap.compress(Bitmap.CompressFormat.PNG, 100, out)
        }
    }
    
    /**
     * Save bitmap as JPEG (better compatibility and smaller size)
     */
    private fun saveJpeg(bitmap: Bitmap, file: File, quality: Int = 95): Boolean {
        return try {
            FileOutputStream(file).use { out ->
                bitmap.compress(Bitmap.CompressFormat.JPEG, quality, out)
            }
            Log.d(TAG, "Saved JPEG: ${file.name} (${file.length() / 1024}KB)")
            true
        } catch (e: Exception) {
            Log.e(TAG, "Failed to save JPEG: ${file.name}", e)
            false
        }
    }
    
    /**
     * Get current session statistics
     */
    fun getSessionStats(): M2SessionStats = sessionStats
    
    /**
     * Reset session statistics
     */
    fun resetStats() {
        sessionStats = M2SessionStats(0, 0, 0, 0)
        frameTimes.clear()
    }
}